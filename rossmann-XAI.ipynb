{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "FROM_SCRATCH = True"
   ],
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "execution_count": 62,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "9.1.1 Preparing the data.\n",
    "Weâ€™re using the wine-quality dataset, a numeric tabular dataset containing features that refer to the chemical composition of wines and quality ratings. To make this a simple classification task, we bucket all wines with ratings greater\n",
    "than five as good, and the rest we label bad. We also normalize all the features."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexd\\AppData\\Local\\Temp\\ipykernel_16352\\2235936024.py:2: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train = pd.read_csv('input/train.csv',parse_dates=[2])\n"
     ]
    }
   ],
   "source": [
    "store = pd.read_csv('input/store.csv')\n",
    "train = pd.read_csv('input/train.csv',parse_dates=[2])\n",
    "test = pd.read_csv('input/test.csv',parse_dates=[3])\n",
    "# fillna in store with 0 has better result than median()\n",
    "# Aufbereiten der daten\n",
    "store.fillna(0, inplace=True)\n",
    "# fill missing values in test with 1\n",
    "# Aufbereiten der Daten\n",
    "test.fillna(value = 1, inplace = True)\n",
    "# merge data with store\n",
    "# Alles in eine Tabelle\n",
    "train = pd.merge(train, store, on='Store')\n",
    "test = pd.merge(test, store, on='Store')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "   Store  DayOfWeek       Date  Sales  Customers  Open  Promo StateHoliday  \\\n0      1          5 2015-07-31   5263        555     1      1            0   \n1      1          4 2015-07-30   5020        546     1      1            0   \n2      1          3 2015-07-29   4782        523     1      1            0   \n3      1          2 2015-07-28   5011        560     1      1            0   \n4      1          1 2015-07-27   6102        612     1      1            0   \n\n   SchoolHoliday StoreType Assortment  CompetitionDistance  \\\n0              1         c          a               1270.0   \n1              1         c          a               1270.0   \n2              1         c          a               1270.0   \n3              1         c          a               1270.0   \n4              1         c          a               1270.0   \n\n   CompetitionOpenSinceMonth  CompetitionOpenSinceYear  Promo2  \\\n0                        9.0                    2008.0       0   \n1                        9.0                    2008.0       0   \n2                        9.0                    2008.0       0   \n3                        9.0                    2008.0       0   \n4                        9.0                    2008.0       0   \n\n   Promo2SinceWeek  Promo2SinceYear PromoInterval  \n0              0.0              0.0             0  \n1              0.0              0.0             0  \n2              0.0              0.0             0  \n3              0.0              0.0             0  \n4              0.0              0.0             0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Store</th>\n      <th>DayOfWeek</th>\n      <th>Date</th>\n      <th>Sales</th>\n      <th>Customers</th>\n      <th>Open</th>\n      <th>Promo</th>\n      <th>StateHoliday</th>\n      <th>SchoolHoliday</th>\n      <th>StoreType</th>\n      <th>Assortment</th>\n      <th>CompetitionDistance</th>\n      <th>CompetitionOpenSinceMonth</th>\n      <th>CompetitionOpenSinceYear</th>\n      <th>Promo2</th>\n      <th>Promo2SinceWeek</th>\n      <th>Promo2SinceYear</th>\n      <th>PromoInterval</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>5</td>\n      <td>2015-07-31</td>\n      <td>5263</td>\n      <td>555</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>c</td>\n      <td>a</td>\n      <td>1270.0</td>\n      <td>9.0</td>\n      <td>2008.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>4</td>\n      <td>2015-07-30</td>\n      <td>5020</td>\n      <td>546</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>c</td>\n      <td>a</td>\n      <td>1270.0</td>\n      <td>9.0</td>\n      <td>2008.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>2015-07-29</td>\n      <td>4782</td>\n      <td>523</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>c</td>\n      <td>a</td>\n      <td>1270.0</td>\n      <td>9.0</td>\n      <td>2008.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>2</td>\n      <td>2015-07-28</td>\n      <td>5011</td>\n      <td>560</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>c</td>\n      <td>a</td>\n      <td>1270.0</td>\n      <td>9.0</td>\n      <td>2008.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>2015-07-27</td>\n      <td>6102</td>\n      <td>612</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>c</td>\n      <td>a</td>\n      <td>1270.0</td>\n      <td>9.0</td>\n      <td>2008.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Store  DayOfWeek       Date  Sales  Customers  Open  Promo  \\\n",
      "0            1          5 2015-07-31   5263        555     1      1   \n",
      "1            1          4 2015-07-30   5020        546     1      1   \n",
      "2            1          3 2015-07-29   4782        523     1      1   \n",
      "3            1          2 2015-07-28   5011        560     1      1   \n",
      "4            1          1 2015-07-27   6102        612     1      1   \n",
      "...        ...        ...        ...    ...        ...   ...    ...   \n",
      "1017204   1115          6 2013-01-05   4771        339     1      0   \n",
      "1017205   1115          5 2013-01-04   4540        326     1      0   \n",
      "1017206   1115          4 2013-01-03   4297        300     1      0   \n",
      "1017207   1115          3 2013-01-02   3697        305     1      0   \n",
      "1017208   1115          2 2013-01-01      0          0     0      0   \n",
      "\n",
      "        StateHoliday  SchoolHoliday StoreType Assortment  CompetitionDistance  \\\n",
      "0                  0              1         c          a               1270.0   \n",
      "1                  0              1         c          a               1270.0   \n",
      "2                  0              1         c          a               1270.0   \n",
      "3                  0              1         c          a               1270.0   \n",
      "4                  0              1         c          a               1270.0   \n",
      "...              ...            ...       ...        ...                  ...   \n",
      "1017204            0              1         d          c               5350.0   \n",
      "1017205            0              1         d          c               5350.0   \n",
      "1017206            0              1         d          c               5350.0   \n",
      "1017207            0              1         d          c               5350.0   \n",
      "1017208            a              1         d          c               5350.0   \n",
      "\n",
      "         CompetitionOpenSinceMonth  CompetitionOpenSinceYear  Promo2  \\\n",
      "0                              9.0                    2008.0       0   \n",
      "1                              9.0                    2008.0       0   \n",
      "2                              9.0                    2008.0       0   \n",
      "3                              9.0                    2008.0       0   \n",
      "4                              9.0                    2008.0       0   \n",
      "...                            ...                       ...     ...   \n",
      "1017204                        0.0                       0.0       1   \n",
      "1017205                        0.0                       0.0       1   \n",
      "1017206                        0.0                       0.0       1   \n",
      "1017207                        0.0                       0.0       1   \n",
      "1017208                        0.0                       0.0       1   \n",
      "\n",
      "         Promo2SinceWeek  Promo2SinceYear     PromoInterval Class  \n",
      "0                    0.0              0.0                 0     2  \n",
      "1                    0.0              0.0                 0     1  \n",
      "2                    0.0              0.0                 0     1  \n",
      "3                    0.0              0.0                 0     1  \n",
      "4                    0.0              0.0                 0     2  \n",
      "...                  ...              ...               ...   ...  \n",
      "1017204             22.0           2012.0  Mar,Jun,Sept,Dec     1  \n",
      "1017205             22.0           2012.0  Mar,Jun,Sept,Dec     1  \n",
      "1017206             22.0           2012.0  Mar,Jun,Sept,Dec     1  \n",
      "1017207             22.0           2012.0  Mar,Jun,Sept,Dec     0  \n",
      "1017208             22.0           2012.0  Mar,Jun,Sept,Dec     0  \n",
      "\n",
      "[1017209 rows x 19 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"\\ntrain['Class'] = 3\\nclasses = [0, 1, 2, 3, 4, 5, 6]\\n\\nfor Id in train['Store'].unique():\\n    store_df = train[train['Store'] == Id]\\n    for DayOfWeek in  store_df['DayOfWeek'].unique():\\n        if DayOfWeek != 7:\\n            store_df_day = store_df[store_df['DayOfWeek']== DayOfWeek]\\n            quantile = np.arange(1, 7) / 7\\n            store_quan = np.arange(0, 8)\\n            store_quan[0] = -1\\n            for index, x in enumerate(quantile):\\n                store_quan[index+1] = store_df_day['Sales'].quantile(x)\\n            store_quan[7] = store_df_day['Sales'].max()\\n            # befÃ¼llen der Werte Klasse fÃ¼r bestimmten Tag und bestimmten Store\\n            # for store in store_df_day:\\n            store_df_day['Class'] = pd.cut(store_df_day['Sales'], store_quan, labels=classes)\\n            train.loc[(train['Store'] == Id) & (train['DayOfWeek'] == DayOfWeek), 'Class'] = store_df_day['Class'].to_numpy()\\n\""
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = [0, 1, 2, 3, 4, 5]\n",
    "train['Class'] = pd.qcut(train['Sales'], q=7, duplicates='drop', labels=classes)\n",
    "print(train)\n",
    "\"\"\"\n",
    "train['Class'] = 3\n",
    "classes = [0, 1, 2, 3, 4, 5, 6]\n",
    "\n",
    "for Id in train['Store'].unique():\n",
    "    store_df = train[train['Store'] == Id]\n",
    "    for DayOfWeek in  store_df['DayOfWeek'].unique():\n",
    "        if DayOfWeek != 7:\n",
    "            store_df_day = store_df[store_df['DayOfWeek']== DayOfWeek]\n",
    "            quantile = np.arange(1, 7) / 7\n",
    "            store_quan = np.arange(0, 8)\n",
    "            store_quan[0] = -1\n",
    "            for index, x in enumerate(quantile):\n",
    "                store_quan[index+1] = store_df_day['Sales'].quantile(x)\n",
    "            store_quan[7] = store_df_day['Sales'].max()\n",
    "            # befÃ¼llen der Werte Klasse fÃ¼r bestimmten Tag und bestimmten Store\n",
    "            # for store in store_df_day:\n",
    "            store_df_day['Class'] = pd.cut(store_df_day['Sales'], store_quan, labels=classes)\n",
    "            train.loc[(train['Store'] == Id) & (train['DayOfWeek'] == DayOfWeek), 'Class'] = store_df_day['Class'].to_numpy()\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "Store                        0\nDayOfWeek                    0\nDate                         0\nSales                        0\nCustomers                    0\nOpen                         0\nPromo                        0\nStateHoliday                 0\nSchoolHoliday                0\nStoreType                    0\nAssortment                   0\nCompetitionDistance          0\nCompetitionOpenSinceMonth    0\nCompetitionOpenSinceYear     0\nPromo2                       0\nPromo2SinceWeek              0\nPromo2SinceYear              0\nPromoInterval                0\nClass                        0\ndtype: int64"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexd\\AppData\\Local\\Temp\\ipykernel_16352\\1571324377.py:15: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  data['WeekOfYear'] = data.Date.dt.weekofyear\n",
      "C:\\Users\\alexd\\AppData\\Local\\Temp\\ipykernel_16352\\1571324377.py:15: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  data['WeekOfYear'] = data.Date.dt.weekofyear\n"
     ]
    }
   ],
   "source": [
    "# process train and test\n",
    "# aufbereiten der daten, neue Spalten und manche werden entfernt\n",
    "def process(data, isTest = False):\n",
    "    # label encode some features\n",
    "    mappings = {'0':0, 'a':1, 'b':2, 'c':3, 'd':4}\n",
    "    # buchstaben zu zahlen\n",
    "    data.StoreType.replace(mappings, inplace=True)\n",
    "    data.Assortment.replace(mappings, inplace=True)\n",
    "    data.StateHoliday.replace(mappings, inplace=True)\n",
    "\n",
    "    # extract some features from date column\n",
    "    data['Month'] = data.Date.dt.month\n",
    "    data['Year'] = data.Date.dt.year\n",
    "    data['Day'] = data.Date.dt.day\n",
    "    data['WeekOfYear'] = data.Date.dt.weekofyear\n",
    "\n",
    "    # calculate competiter open time in months\n",
    "    data['CompetitionOpen'] = 12 * (data.Year - data.CompetitionOpenSinceYear) + \\\n",
    "        (data.Month - data.CompetitionOpenSinceMonth)\n",
    "    data['CompetitionOpen'] = data['CompetitionOpen'].apply(lambda x: x if x > 0 else 0)\n",
    "\n",
    "    # calculate promo2 open time in months\n",
    "    data['PromoOpen'] = 12 * (data.Year - data.Promo2SinceYear) + \\\n",
    "        (data.WeekOfYear - data.Promo2SinceWeek) / 4.0\n",
    "    data['PromoOpen'] = data['PromoOpen'].apply(lambda x: x if x > 0 else 0)\n",
    "\n",
    "    # Indicate whether the month is in promo interval\n",
    "    month2str = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', \\\n",
    "             7:'Jul', 8:'Aug', 9:'Sept', 10:'Oct', 11:'Nov', 12:'Dec'}\n",
    "    data['month_str'] = data.Month.map(month2str)\n",
    "\n",
    "    def check(row):\n",
    "        if isinstance(row['PromoInterval'],str) and row['month_str'] in row['PromoInterval']:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    data['IsPromoMonth'] =  data.apply(lambda row: check(row),axis=1)\n",
    "\n",
    "    # select the features we need\n",
    "    features = ['Store', 'DayOfWeek', 'Promo', 'StateHoliday', 'SchoolHoliday',\n",
    "       'StoreType', 'Assortment', 'CompetitionDistance',\n",
    "       'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2',\n",
    "       'Promo2SinceWeek', 'Promo2SinceYear', 'Year', 'Month', 'Day',\n",
    "       'WeekOfYear', 'CompetitionOpen', 'PromoOpen', 'IsPromoMonth']\n",
    "    if not isTest:\n",
    "        features.append('Sales')\n",
    "        features.append('Class')\n",
    "\n",
    "    data = data[features]\n",
    "    return data\n",
    "\n",
    "train = train.sort_values(['Date'],ascending = False)\n",
    "train = process(train)\n",
    "test = process(test,isTest = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "   Store  DayOfWeek  Promo  StateHoliday  SchoolHoliday  StoreType  \\\n0      1          4      1             0              0          3   \n1      1          3      1             0              0          3   \n2      1          2      1             0              0          3   \n3      1          1      1             0              0          3   \n4      1          7      0             0              0          3   \n\n   Assortment  CompetitionDistance  CompetitionOpenSinceMonth  \\\n0           1               1270.0                        9.0   \n1           1               1270.0                        9.0   \n2           1               1270.0                        9.0   \n3           1               1270.0                        9.0   \n4           1               1270.0                        9.0   \n\n   CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  Promo2SinceYear  Year  \\\n0                    2008.0       0              0.0              0.0  2015   \n1                    2008.0       0              0.0              0.0  2015   \n2                    2008.0       0              0.0              0.0  2015   \n3                    2008.0       0              0.0              0.0  2015   \n4                    2008.0       0              0.0              0.0  2015   \n\n   Month  Day  WeekOfYear  CompetitionOpen  PromoOpen  IsPromoMonth  \n0      9   17          38             84.0   24189.50             0  \n1      9   16          38             84.0   24189.50             0  \n2      9   15          38             84.0   24189.50             0  \n3      9   14          38             84.0   24189.50             0  \n4      9   13          37             84.0   24189.25             0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Store</th>\n      <th>DayOfWeek</th>\n      <th>Promo</th>\n      <th>StateHoliday</th>\n      <th>SchoolHoliday</th>\n      <th>StoreType</th>\n      <th>Assortment</th>\n      <th>CompetitionDistance</th>\n      <th>CompetitionOpenSinceMonth</th>\n      <th>CompetitionOpenSinceYear</th>\n      <th>Promo2</th>\n      <th>Promo2SinceWeek</th>\n      <th>Promo2SinceYear</th>\n      <th>Year</th>\n      <th>Month</th>\n      <th>Day</th>\n      <th>WeekOfYear</th>\n      <th>CompetitionOpen</th>\n      <th>PromoOpen</th>\n      <th>IsPromoMonth</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1270.0</td>\n      <td>9.0</td>\n      <td>2008.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2015</td>\n      <td>9</td>\n      <td>17</td>\n      <td>38</td>\n      <td>84.0</td>\n      <td>24189.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1270.0</td>\n      <td>9.0</td>\n      <td>2008.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2015</td>\n      <td>9</td>\n      <td>16</td>\n      <td>38</td>\n      <td>84.0</td>\n      <td>24189.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1270.0</td>\n      <td>9.0</td>\n      <td>2008.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2015</td>\n      <td>9</td>\n      <td>15</td>\n      <td>38</td>\n      <td>84.0</td>\n      <td>24189.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1270.0</td>\n      <td>9.0</td>\n      <td>2008.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2015</td>\n      <td>9</td>\n      <td>14</td>\n      <td>38</td>\n      <td>84.0</td>\n      <td>24189.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1270.0</td>\n      <td>9.0</td>\n      <td>2008.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2015</td>\n      <td>9</td>\n      <td>13</td>\n      <td>37</td>\n      <td>84.0</td>\n      <td>24189.25</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "        Store  DayOfWeek  Promo  StateHoliday  SchoolHoliday  StoreType  \\\n0           1          5      1             0              1          3   \n679364    747          5      1             0              1          3   \n702362    772          5      1             0              1          4   \n683890    752          5      1             0              1          1   \n17714      20          5      1             0              0          4   \n\n        Assortment  CompetitionDistance  CompetitionOpenSinceMonth  \\\n0                1               1270.0                        9.0   \n679364           3              45740.0                        8.0   \n702362           3               1850.0                        0.0   \n683890           1                970.0                        3.0   \n17714            1               2340.0                        5.0   \n\n        CompetitionOpenSinceYear  ...  Promo2SinceYear  Year  Month  Day  \\\n0                         2008.0  ...              0.0  2015      7   31   \n679364                    2008.0  ...              0.0  2015      7   31   \n702362                       0.0  ...              0.0  2015      7   31   \n683890                    2013.0  ...           2013.0  2015      7   31   \n17714                     2009.0  ...           2014.0  2015      7   31   \n\n        WeekOfYear  CompetitionOpen  PromoOpen  IsPromoMonth  Sales  Class  \n0               31             82.0   24187.75             0   5263      2  \n679364          31             83.0   24187.75             0  10708      5  \n702362          31          24187.0   24187.75             0   5224      1  \n683890          31             28.0      24.00             0   7763      4  \n17714           31             74.0       9.75             1   9593      5  \n\n[5 rows x 22 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Store</th>\n      <th>DayOfWeek</th>\n      <th>Promo</th>\n      <th>StateHoliday</th>\n      <th>SchoolHoliday</th>\n      <th>StoreType</th>\n      <th>Assortment</th>\n      <th>CompetitionDistance</th>\n      <th>CompetitionOpenSinceMonth</th>\n      <th>CompetitionOpenSinceYear</th>\n      <th>...</th>\n      <th>Promo2SinceYear</th>\n      <th>Year</th>\n      <th>Month</th>\n      <th>Day</th>\n      <th>WeekOfYear</th>\n      <th>CompetitionOpen</th>\n      <th>PromoOpen</th>\n      <th>IsPromoMonth</th>\n      <th>Sales</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1270.0</td>\n      <td>9.0</td>\n      <td>2008.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>2015</td>\n      <td>7</td>\n      <td>31</td>\n      <td>31</td>\n      <td>82.0</td>\n      <td>24187.75</td>\n      <td>0</td>\n      <td>5263</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>679364</th>\n      <td>747</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>45740.0</td>\n      <td>8.0</td>\n      <td>2008.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>2015</td>\n      <td>7</td>\n      <td>31</td>\n      <td>31</td>\n      <td>83.0</td>\n      <td>24187.75</td>\n      <td>0</td>\n      <td>10708</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>702362</th>\n      <td>772</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>3</td>\n      <td>1850.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>2015</td>\n      <td>7</td>\n      <td>31</td>\n      <td>31</td>\n      <td>24187.0</td>\n      <td>24187.75</td>\n      <td>0</td>\n      <td>5224</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>683890</th>\n      <td>752</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>970.0</td>\n      <td>3.0</td>\n      <td>2013.0</td>\n      <td>...</td>\n      <td>2013.0</td>\n      <td>2015</td>\n      <td>7</td>\n      <td>31</td>\n      <td>31</td>\n      <td>28.0</td>\n      <td>24.00</td>\n      <td>0</td>\n      <td>7763</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>17714</th>\n      <td>20</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2340.0</td>\n      <td>5.0</td>\n      <td>2009.0</td>\n      <td>...</td>\n      <td>2014.0</td>\n      <td>2015</td>\n      <td>7</td>\n      <td>31</td>\n      <td>31</td>\n      <td>74.0</td>\n      <td>9.75</td>\n      <td>1</td>\n      <td>9593</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 22 columns</p>\n</div>"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "featuresR  = ['Store', 'DayOfWeek', 'Promo', 'StateHoliday', 'SchoolHoliday',\n",
    "       'StoreType', 'Assortment', 'CompetitionDistance',\n",
    "       'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2',\n",
    "       'Promo2SinceWeek', 'Promo2SinceYear', 'Year', 'Month', 'Day',\n",
    "       'WeekOfYear', 'CompetitionOpen', 'PromoOpen', 'IsPromoMonth']\n",
    "train_data = train[featuresR].to_numpy()\n",
    "test_data = test[featuresR].to_numpy()\n",
    "labels_train = train[['Class']].to_numpy()\n",
    "\n",
    "X_trainR, X_testR, y_trainR, y_testR = train_test_split(train_data, labels_train, random_state=0)\n",
    "X_trainR, X_testR = X_trainR.astype('float32'), X_testR.astype('float32')\n",
    "y_train_labR, y_test_labR = y_trainR[:, 0], y_testR[:, 0]\n",
    "y_trainR, y_testR = y_trainR[:, 1:].astype('float32'), y_testR[:, 1:].astype('float32')\n",
    "scalerR = StandardScaler()\n",
    "scalerR.fit(X_trainR)\n",
    "category_map = {1: [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"], 2:[\"PromoNo\", \"PromoYes\"], 3: [\"NoStateHoliday\", \"PublicHoliday\", \"EasterHoliday\", \"ChristmasHoliday\"],\n",
    "                4:[\"SchoolHolidayNo\", \"SchoolHolidayYes\"], 5: [\"StoreTypeA\", \"StoreTypeB\", \"StoreTypeC\", \"StoreTypeD\", \"StoreTypeE\"], 6:[\"Basic\", \"Extra\", \"Extended\"], 8:[\"None\",\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"], 10: [\"NoPromo2\", \"Promo2\"], 14: [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"], 19: [\"NoPromoMonth\", \"PromoMonth\"] }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "column_values = set(train['CompetitionOpenSinceMonth'])\n",
    "print(column_values)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Select good wine instance\n",
    "We partition the dataset into good and bad portions and select an instance of interest. Iâ€™ve chosen it to be a good quality\n",
    "wine.\n",
    "Note that bad wines are class 1 and correspond to the second model output being high, whereas good wines are class\n",
    "0 and correspond to the first model output being high."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# bad_days = np.array([a for a, b in zip(X_trainR, y_trainR) if b[1] == 1])\n",
    "# good_days = np.array([a for a, b in zip(X_trainR, y_trainR) if b[1] == 0])\n",
    "xR = np.array([[747,5,1,0,1,3,3,45740.0,8.0,2008.0,1,0.0,0.0,2015,7,31,31,83.0,24187.75,0]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "9.1.2 Training models\n",
    "Creating an Autoencoder\n",
    "For some of the explainers, we need an autoencoder to check whether example instances are close to the training data\n",
    "distribution or not."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Random Forest Model\n",
    "We need a tree-based model to get results for the tree SHAP explainer. Hence we train a random forest on the winequality dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "XGBoost Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "# define eval metrics\n",
    "# Mittleres Abweichungsquadrat\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def rmspe(y, yhat):\n",
    "    return np.sqrt(np.mean((yhat/y-1) ** 2))\n",
    "# expm1 ist umkehr von log1p\n",
    "def rmspe_xg(yhat, y):\n",
    "    yhat = yhat\n",
    "    y = y\n",
    "    y = np.expm1(y.get_label())\n",
    "    yhat = np.expm1(yhat)\n",
    "    return \"rmspe\", rmspe(y,yhat)\n",
    "def rmse(ytest, y):\n",
    "    return np.sqrt(mean_squared_error(ytest, y))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "y_train_xgb = y_train_labR\n",
    "y_test_xgb = y_test_labR"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "# Funktionierendes Modell\n",
    "\"\"\"\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "\n",
    "def make_xgb_modelR():\n",
    "    params = {\"objective\": \"multi:softmax\", # for linear regression\n",
    "              \"booster\" : \"gbtree\",   # use tree based models\n",
    "              \"eta\": 0.03,   # learning rate\n",
    "              \"max_depth\": 10,    # maximum depth of a tree\n",
    "              \"subsample\": 0.9,    # Subsample ratio of the training instances\n",
    "              \"colsample_bytree\": 0.8,   # Subsample ratio of columns when constructing each tree\n",
    "              \"n_estimators\": 100,\n",
    "              \"silent\": 1,   # silent mode\n",
    "              \"seed\": 27,   # Random number seed\n",
    "              \"num_class\": 6, #Anzahl Klassen\n",
    "              \"reg_alpha\": 0.01,\n",
    "              \"gamma\": 0,\n",
    "              \"predictor\": \"gpu_predictor\",\n",
    "              \"gpu_id\": 0,\n",
    "              \"tree_method\": \"gpu_hist\",\n",
    "              #'eval_metric': 'auc'\n",
    "              }\n",
    "    # anzahl trainingsrunden\n",
    "    num_boost_round = 4000\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_trainR, y_train_xgb)\n",
    "    dtest = xgb.DMatrix(X_testR, y_test_xgb)\n",
    "    watchlist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "    # train the xgboost model\n",
    "    model = xgb.train(params, dtrain, num_boost_round, evals=watchlist, \\\n",
    "      early_stopping_rounds= 10, verbose_eval=True)\n",
    "    y_predR = np.rint(model.predict(xgb.DMatrix(X_testR)))\n",
    "    print(y_predR)\n",
    "    print('accuracy_score:', accuracy_score(y_predR, y_test_xgb))\n",
    "    # print('f1_score:', f1_score(y_predR, y_test_xgb))\n",
    "\n",
    "    return model\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "# OnevsRestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "\n",
    "def make_xgb_modelR():\n",
    "    params = {\"objective\": \"multi:softmax\", # for linear regression\n",
    "              \"booster\" : \"gbtree\",   # use tree based models\n",
    "              \"eta\": 0.03,   # learning rate\n",
    "              \"max_depth\": 10,    # maximum depth of a tree\n",
    "              \"subsample\": 0.9,    # Subsample ratio of the training instances\n",
    "              \"colsample_bytree\": 0.8,   # Subsample ratio of columns when constructing each tree\n",
    "              \"n_estimators\": 100,\n",
    "              \"silent\": 1,   # silent mode\n",
    "              \"seed\": 27,   # Random number seed\n",
    "              \"num_class\": 6, #Anzahl Klassen\n",
    "              \"reg_alpha\": 0.01,\n",
    "              \"gamma\": 0,\n",
    "              \"predictor\": \"gpu_predictor\",\n",
    "              \"gpu_id\": 0,\n",
    "              \"tree_method\": \"gpu_hist\",\n",
    "              #'eval_metric': 'auc'\n",
    "              }\n",
    "    # anzahl trainingsrunden\n",
    "    num_boost_round = 4000\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_trainR, y_train_xgb)\n",
    "    dtest = xgb.DMatrix(X_testR, y_test_xgb)\n",
    "    watchlist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "    # train the xgboost model\n",
    "\n",
    "    #XGBClassifier(booster = 'gbtree', objective= 'multi:softmax', eta = 0.03, max_depth = 10,\n",
    "    #                                          subsample = 0.9, colsample_bytree = 0.8, n_estimators = 100, silent = 0, seed = 10,\n",
    "    #                                          num_class = 6, predictor = 'gpu_predictor', gpu_id = 0, tree_method = 'gpu_hist',\n",
    "     #                                         num_round = 4000)\n",
    "\n",
    "    xgbc = xgb.XGBClassifier(num_round = 1000, booster = 'gbtree', objective= 'multi:softmax', learning_rate = 0.03, max_depth = 10,\n",
    "                                              subsample = 0.9, colsample_bytree = 0.8, n_estimators = 100, seed = 10,\n",
    "                                              num_class = 6, predictor = 'gpu_predictor', gpu_id = 0, tree_method = 'gpu_hist')\n",
    "\n",
    "    model = OneVsRestClassifier(estimator=xgbc)\n",
    "    p = model.get_params(deep=True)\n",
    "    model.fit(X_trainR,y_train_xgb)\n",
    "    y_predR = model.predict(X_testR)\n",
    "    \"\"\"\n",
    "    model = xgb.train(params, dtrain, num_boost_round, evals=watchlist, \\\n",
    "      early_stopping_rounds= 10, verbose_eval=True)\n",
    "    y_predR = np.rint(model.predict(xgb.DMatrix(X_testR)))\n",
    "    \"\"\"\n",
    "    print(y_predR)\n",
    "    #print('accuracy_score:', accuracy_score(y_predR, y_test_xgb))\n",
    "    # print('f1_score:', f1_score(y_predR, y_test_xgb))\n",
    "\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nimport xgboost as xgb\\n\\ndef make_xgb_modelR():\\n    params = {\"objective\": \"reg:linear\", # for linear regression\\n              \"booster\" : \"gbtree\",   # use tree based models\\n              \"eta\": 0.05,   # learning rate\\n              \"max_depth\": 15,    # maximum depth of a tree\\n              \"subsample\": 0.9,    # Subsample ratio of the training instances\\n              \"colsample_bytree\": 0.7,   # Subsample ratio of columns when constructing each tree\\n              \"n_estimators\": 100,\\n              \"silent\": 1,   # silent mode\\n              \"seed\": 10,   # Random number seed\\n              #\"num_class\": 7\\n              #\"gpu_id\": 0,\\n              #\"tree_method\": \"gpu_hist\"\\n              }\\n    # anzahl trainingsrunden\\n    num_boost_round = 100\\n\\n    dtrain = xgb.DMatrix(X_trainR, y_train_xgb)\\n    dtest = xgb.DMatrix(X_testR, y_test_xgb)\\n    watchlist = [(dtrain, \\'train\\'), (dtest, \\'eval\\')]\\n    # train the xgboost model\\n    model = xgb.train(params, dtrain, num_boost_round, evals=watchlist,       early_stopping_rounds= 100, verbose_eval=True)\\n    y_predR = np.rint(model.predict(xgb.DMatrix(X_testR)))\\n    print(y_predR)\\n    print(\\'accuracy_score:\\', accuracy_score(y_predR, y_test_xgb))\\n    # print(\\'f1_score:\\', f1_score(y_predR, y_test_xgb))\\n\\n    return model\\n'"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Altes Modell\n",
    "\n",
    "\"\"\"\n",
    "import xgboost as xgb\n",
    "\n",
    "def make_xgb_modelR():\n",
    "    params = {\"objective\": \"reg:linear\", # for linear regression\n",
    "              \"booster\" : \"gbtree\",   # use tree based models\n",
    "              \"eta\": 0.05,   # learning rate\n",
    "              \"max_depth\": 15,    # maximum depth of a tree\n",
    "              \"subsample\": 0.9,    # Subsample ratio of the training instances\n",
    "              \"colsample_bytree\": 0.7,   # Subsample ratio of columns when constructing each tree\n",
    "              \"n_estimators\": 100,\n",
    "              \"silent\": 1,   # silent mode\n",
    "              \"seed\": 10,   # Random number seed\n",
    "              #\"num_class\": 7\n",
    "              #\"gpu_id\": 0,\n",
    "              #\"tree_method\": \"gpu_hist\"\n",
    "              }\n",
    "    # anzahl trainingsrunden\n",
    "    num_boost_round = 100\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_trainR, y_train_xgb)\n",
    "    dtest = xgb.DMatrix(X_testR, y_test_xgb)\n",
    "    watchlist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "    # train the xgboost model\n",
    "    model = xgb.train(params, dtrain, num_boost_round, evals=watchlist, \\\n",
    "      early_stopping_rounds= 100, verbose_eval=True)\n",
    "    y_predR = np.rint(model.predict(xgb.DMatrix(X_testR)))\n",
    "    print(y_predR)\n",
    "    print('accuracy_score:', accuracy_score(y_predR, y_test_xgb))\n",
    "    # print('f1_score:', f1_score(y_predR, y_test_xgb))\n",
    "\n",
    "    return model\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tensorflow Model\n",
    "Finally, we also train a TensorFlow model.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:48:14] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0082aa9edf5298699-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"num_round\" } are not used.\n",
      "\n",
      "[16:48:20] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0082aa9edf5298699-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"num_round\" } are not used.\n",
      "\n",
      "[16:48:25] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0082aa9edf5298699-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"num_round\" } are not used.\n",
      "\n",
      "[16:48:30] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0082aa9edf5298699-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"num_round\" } are not used.\n",
      "\n",
      "[16:48:35] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0082aa9edf5298699-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"num_round\" } are not used.\n",
      "\n",
      "[16:48:40] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0082aa9edf5298699-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"num_round\" } are not used.\n",
      "\n",
      "[1 3 0 ... 3 4 0]\n"
     ]
    }
   ],
   "source": [
    "# Modell wird schon passend gespeichert @Bene :)\n",
    "import os.path\n",
    "\n",
    "if FROM_SCRATCH or not os.path.isfile('modelXGBR.json'):\n",
    "    modelXGBR = make_xgb_modelR()\n",
    "    #modelXGBR.save_model('modelXGBR.json')\n",
    "else:\n",
    "    modelXGBR = xgb.Booster()\n",
    "    modelXGBR.load_model('modelXGBR.json')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#modelXGBR = make_xgb_modelR()\n",
    "#modelXGBR.save_model(\"modelXGBR.json\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 0 ... 4 4 0]\n",
      "[1. 3. 0. ... 3. 4. 0.]\n",
      "RMSE: 1.0628\n"
     ]
    }
   ],
   "source": [
    "#y_pred = np.rint(modelXGBR.predict(xgb.DMatrix(X_testR)))\n",
    "y_pred = np.rint(modelXGBR.predict(X_testR))\n",
    "print(y_test_xgb)\n",
    "print(y_pred)\n",
    "error = rmse(y_test_xgb, y_pred)\n",
    "print('RMSE: {:.4f}'.format(error))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load/Make models\n",
    "We save and load the same models each time to ensure stable results. If they donâ€™t exist we create new ones. If you\n",
    "want to generate new models on each notebook run, then set FROM_SCRATCH=True."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import shap\n",
    "\n",
    "dtrain = xgb.DMatrix(X_trainR, y_train_xgb)\n",
    "modelXGBR.set_param({\"predictor\": \"gpu_predictor\"})\n",
    "shap_values = modelXGBR.predict(dtrain, pred_contribs=True)\n",
    "shap_interaction_values = modelXGBR.predict(dtrain, pred_interactions=True)\n",
    "\n",
    "modelXGBR.set_param({\"predictor\": \"gpu_predictor\"})\n",
    "explainer = shap.TreeExplainer(modelXGBR)\n",
    "shap_values = explainer.shap_values(X_trainR)\n",
    "shap.summary_plot(shap_values, X_trainR,max_display= 10, title = 'SHAP', plot_type= 'bar')\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "9.1.3 Util functions\n",
    "These are utility functions for exploring results. The first shows two instances of the data side by side and compares\n",
    "the difference. Weâ€™ll use this to see how the counterfactuals differ from their original instances. The second function\n",
    "plots the importance of each feature. This will be useful for visualizing the attribution methods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def compare_instances(x, cf):\n",
    "\n",
    "    #Show the difference in values between two instances.\n",
    "\n",
    "    x = x.astype('float64')\n",
    "    cf = cf.astype('float64')\n",
    "    for f, v1, v2 in zip(features, x[0], cf[0]):\n",
    "        print(f'{f:<25} instance: {round(v1, 3):^10} counter factual: {round(v2, 3):^10} difference: {round(v2, 7):^5}')\n",
    "\n",
    "def plot_importance(feat_imp, feat_names, class_idx, **kwargs):\n",
    "\n",
    "    #Create a horizontal barchart of feature effects, sorted by their magnitude.\n",
    "\n",
    "    df = pd.DataFrame(data=feat_imp, columns=feat_names).sort_values(by=0, axis='columns')\n",
    "    feat_imp, feat_names = df.values[0], df.columns\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    y_pos = np.arange(len(feat_imp))\n",
    "    ax.barh(y_pos, feat_imp)\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(feat_names, fontsize=15)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel(f'Feature effects for class {class_idx}', fontsize=15)\n",
    "    return ax, fig\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "9.1.5 Local Necessary Features\n",
    "Anchors\n",
    "Anchors tell us what features need to stay the same for a specific instance for the model to give the same classification.\n",
    "In the case of a trained image classification model, an anchor for a given instance would be a minimal subset of the\n",
    "image that the model uses to make its decision.\n",
    "Here we apply Anchors to the tensor flow model trained on the wine-quality dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "from alibi.explainers import AnchorTabular\n",
    "predict_fnR = lambda x: modelR.predict(scalerR.transform(x))\n",
    "explainerR = AnchorTabular(predict_fnR, featuresR, categorical_names=category_map)\n",
    "explainerR.fit(X_trainR, disc_perc=(25, 50, 75))\n",
    "resultR = explainerR.explain(xR, threshold=0.95)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "category_map = {1: [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"], 2:[\"PromoNo\", \"PromoYes\"], 3: [\"NoStateHoliday\", \"PublicHoliday\", \"EasterHoliday\", \"ChristmasHoliday\"],\n",
    "                4:[\"SchoolHolidayNo\", \"SchoolHolidayYes\"], 5: [\"StoreTypeA\", \"StoreTypeB\", \"StoreTypeC\", \"StoreTypeD\"], 6:[ \"?\", \"Basic\", \"Extra\", \"Extended\"], 8:[\"None\",\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"], 10: [\"NoPromo2\", \"Promo2\"], 14: [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"], 19: [\"NoPromoMonth\", \"PromoMonth\"] }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "category_map = { 1: [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"], 2:[\"PromoNo\", \"PromoYes\"], 3: [\"NoStateHoliday\", \"PublicHoliday\", \"EasterHoliday\", \"ChristmasHoliday\"],\n",
    "                4:[\"SchoolHolidayNo\", \"SchoolHolidayYes\"], 5: [\"?\", \"StoreTypeA\", \"StoreTypeB\", \"StoreTypeC\", \"StoreTypeD\"], 6:[ \"?\", \"Basic\", \"Extra\", \"Extended\"], 8:[\"None\",\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"], 10: [\"NoPromo2\", \"Promo2\"], 14: [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"], 19: [\"NoPromoMonth\", \"PromoMonth\"]}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from alibi.explainers import AnchorTabular\n",
    "predict_xgb = lambda x: np.rint(modelXGBR.predict(xgb.DMatrix(x)))\n",
    "explainerXGB = AnchorTabular(predict_xgb, featuresR, categorical_names=category_map)\n",
    "explainerXGB.fit(X_trainR, disc_perc=(25, 50, 75))\n",
    "resultXGB = explainerXGB.explain(xR, threshold=0.95)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print('Anchor =', resultR.data['anchor'])\n",
    "print('Precision = ', resultR.data['precision'])\n",
    "print('Coverage = ', resultR.data['coverage'])\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Anchor =', resultXGB.data['anchor'])\n",
    "print('Precision = ', resultXGB.data['precision'])\n",
    "print('Coverage = ', resultXGB.data['coverage'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "idx  = 11\n",
    "print(explainerR.predictor(X_testR[idx].reshape(1, -1))[0])\n",
    "explanation = explainerR.explain(X_testR[idx], threshold=0.95)\n",
    "print('Anchor: %s' % (' AND '.join(explanation.anchor)))\n",
    "print('Precision: %.2f' % explanation.precision)\n",
    "print('Coverage: %.2f' % explanation.coverage)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Anchor =', resultXGB.data['anchor'])\n",
    "print('Precision = ', resultXGB.data['precision'])\n",
    "print('Coverage = ', resultXGB.data['coverage'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "idx  = 11\n",
    "print(explainerR.predictor(X_testR[idx].reshape(1, -1))[0])\n",
    "explanation = explainerR.explain(X_testR[idx], threshold=0.95)\n",
    "print('Anchor: %s' % (' AND '.join(explanation.anchor)))\n",
    "print('Precision: %.2f' % explanation.precision)\n",
    "print('Coverage: %.2f' % explanation.coverage)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "idx = 11\n",
    "print(explainerXGB.predictor(X_testR[idx].reshape(1, -1))[0])\n",
    "explanation = explainerXGB.explain(X_testR[idx], threshold=0.95)\n",
    "print('Anchor: %s' % (' AND '.join(explanation.anchor)))\n",
    "print('Precision: %.2f' % explanation.precision)\n",
    "print('Coverage: %.2f' % explanation.coverage)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
