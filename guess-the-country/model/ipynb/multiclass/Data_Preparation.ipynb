{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Preparation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "CvX7ZhwoCIYo",
        "LZhIV572eAEn"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHRPP5pn2BHG"
      },
      "source": [
        "## **Data Understanding & Preparation**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Su5kEaS1WMm"
      },
      "source": [
        "#Import of the relevant libaries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "from google.colab import files    \n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from keras.utils.np_utils import to_categorical \n",
        "from PIL import Image, ImageStat\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G370Oswl2RFj"
      },
      "source": [
        "### Table of contents\n",
        "\n",
        "[Data Understanding](#Data_Understanding)\n",
        "\n",
        "[Data Preparation](#Data_Preparation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80_Q44EG2zpy"
      },
      "source": [
        "### Data Understanding\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "<a id='Data_Understanding'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vPru0B32_Yi"
      },
      "source": [
        "**Data import**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_CuxyR623W1"
      },
      "source": [
        "#The trainingsdata should be found in the following path, separated by country in a folder of the same name\n",
        "DATADIR_Train =\"/content/drive/MyDrive/Images/Train/\"\n",
        "DATADIR_Test =\"/content/drive/MyDrive/Images/Test/\"\n",
        "CATEGORIES = [\"Tel-Aviv\",\"WestJerusalem\" ,\"Berlin\", \"Hamburg\"]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DT4SXiD3Tv_",
        "outputId": "5e1fd96d-b8d9-4094-9be9-2296eeb918fa"
      },
      "source": [
        "#This is only necessary when you use google.colab and the trainingsdata are stored in google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISYK0-EL-0dY"
      },
      "source": [
        "IMAGE_SIZE = 224"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvX7ZhwoCIYo"
      },
      "source": [
        "### Data Preparation\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "<a id='Data_Preparation'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e1lcFleAHMa"
      },
      "source": [
        "Import all images and resize them\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Trainingsdata"
      ],
      "metadata": {
        "id": "hm9LpTNDeEtd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13Dv8jEIABIS"
      },
      "source": [
        "training_data = []\n",
        "\n",
        "def create_training_data():\n",
        "    for category in CATEGORIES:\n",
        "        path = os.path.join(DATADIR_Train, category) # path to the differen images\n",
        "        class_num = CATEGORIES.index(category)\n",
        "        for img in os.listdir(path):\n",
        "            # open the file with opencv\n",
        "              img_arry = cv2.cvtColor(cv2.imread(os.path.join(path, img), cv2.IMREAD_ANYCOLOR), cv2.COLOR_BGR2RGB) #read images with RGB\n",
        "              new_array = cv2.resize(img_arry, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "              training_data.append([new_array, class_num])\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = []\n",
        "def create_test_data():\n",
        "    for category in CATEGORIES:\n",
        "        path = os.path.join(DATADIR_Test, category) # path to the differen images\n",
        "        class_num = CATEGORIES.index(category)\n",
        "        for img in os.listdir(path):\n",
        "            # open the file with opencv\n",
        "              img_arry = cv2.cvtColor(cv2.imread(os.path.join(path, img), cv2.IMREAD_ANYCOLOR), cv2.COLOR_BGR2RGB) #read images with RGB\n",
        "              new_array = cv2.resize(img_arry, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "              test_data.append([new_array, class_num])"
      ],
      "metadata": {
        "id": "7p7uDoSb7Cik"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r58LqIrCT4Pe"
      },
      "source": [
        "create_training_data()\n",
        "create_test_data()\n",
        "#shuffle the data, that not all images with the same label follow one another\n",
        "random.shuffle(training_data)\n",
        "random.shuffle(test_data)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBS_chcbAzH5"
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "IMAGE_SIZE = 224\n",
        "\n",
        "\n",
        "# Split the features and the label in different variables\n",
        "for features, label in training_data:\n",
        "    x_train.append(features)\n",
        "    y_train.append(label)\n",
        "\n",
        "# tensorflow needs an numpy array, so its necessary to transform the data    \n",
        "x_train = np.array(x_train).reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 3)\n",
        "y_train = np.array(to_categorical(y_train))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = []\n",
        "y_test = []\n",
        "IMAGE_SIZE = 224\n",
        "\n",
        "\n",
        "# Split the features and the label in different variables\n",
        "for features, label in test_data:\n",
        "    x_test.append(features)\n",
        "    y_test.append(label)\n",
        "\n",
        "# tensorflow needs an numpy array, so its necessary to transform the data    \n",
        "x_test = np.array(x_test).reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 3)\n",
        "y_test = np.array(to_categorical(y_test))"
      ],
      "metadata": {
        "id": "tbZDC3n996fh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgNNC4RqShUU"
      },
      "source": [
        "Data normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWprcqNkSWq2"
      },
      "source": [
        "x_train = (x_train / 127.5) -1\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcVSlBhHT9Y5"
      },
      "source": [
        "x_test = (x_test/ 127.5) -1 "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbIOeAD2TNkM"
      },
      "source": [
        "Safe Data to use it for the different model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_out = open(\"/content/drive/MyDrive/data/x_train.pickle\",\"wb\")\n",
        "pickle.dump(x_train, pickle_out, protocol=4)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open(\"/content/drive/MyDrive/data/y_train.pickle\",\"wb\")\n",
        "pickle.dump(y_train, pickle_out)\n",
        "pickle_out.close()"
      ],
      "metadata": {
        "id": "SxXoRcaR0k9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_out = open(\"/content/drive/MyDrive/data/x_test.pickle\",\"wb\")\n",
        "pickle.dump(x_test, pickle_out, protocol=4)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open(\"/content/drive/MyDrive/data/y_test.pickle\",\"wb\")\n",
        "pickle.dump(y_test, pickle_out)\n",
        "pickle_out.close()"
      ],
      "metadata": {
        "id": "zujLgqjQO3JD"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}